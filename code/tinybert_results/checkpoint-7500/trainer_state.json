{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 7500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013333333333333334,
      "grad_norm": 3.652322292327881,
      "learning_rate": 1.9736000000000002e-05,
      "loss": 1.3589,
      "step": 100
    },
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 3.291609048843384,
      "learning_rate": 1.9469333333333337e-05,
      "loss": 1.231,
      "step": 200
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.631089925765991,
      "learning_rate": 1.9202666666666668e-05,
      "loss": 1.083,
      "step": 300
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 5.482922554016113,
      "learning_rate": 1.8936e-05,
      "loss": 0.9378,
      "step": 400
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 3.873678207397461,
      "learning_rate": 1.8669333333333334e-05,
      "loss": 0.8276,
      "step": 500
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.7797091007232666,
      "learning_rate": 1.840266666666667e-05,
      "loss": 0.7301,
      "step": 600
    },
    {
      "epoch": 0.09333333333333334,
      "grad_norm": 3.8478918075561523,
      "learning_rate": 1.8136000000000004e-05,
      "loss": 0.6542,
      "step": 700
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 4.494235515594482,
      "learning_rate": 1.7869333333333335e-05,
      "loss": 0.5833,
      "step": 800
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.882845401763916,
      "learning_rate": 1.7602666666666667e-05,
      "loss": 0.5637,
      "step": 900
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 4.798013210296631,
      "learning_rate": 1.7336e-05,
      "loss": 0.514,
      "step": 1000
    },
    {
      "epoch": 0.14666666666666667,
      "grad_norm": 8.392119407653809,
      "learning_rate": 1.7069333333333336e-05,
      "loss": 0.5026,
      "step": 1100
    },
    {
      "epoch": 0.16,
      "grad_norm": 5.5021491050720215,
      "learning_rate": 1.6802666666666668e-05,
      "loss": 0.4858,
      "step": 1200
    },
    {
      "epoch": 0.17333333333333334,
      "grad_norm": 4.2676100730896,
      "learning_rate": 1.6536000000000002e-05,
      "loss": 0.4405,
      "step": 1300
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 7.553258895874023,
      "learning_rate": 1.6269333333333334e-05,
      "loss": 0.4511,
      "step": 1400
    },
    {
      "epoch": 0.2,
      "grad_norm": 7.275564670562744,
      "learning_rate": 1.600266666666667e-05,
      "loss": 0.4262,
      "step": 1500
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 4.63406229019165,
      "learning_rate": 1.5736000000000003e-05,
      "loss": 0.4249,
      "step": 1600
    },
    {
      "epoch": 0.22666666666666666,
      "grad_norm": 1.8278801441192627,
      "learning_rate": 1.5469333333333335e-05,
      "loss": 0.4059,
      "step": 1700
    },
    {
      "epoch": 0.24,
      "grad_norm": 6.4267354011535645,
      "learning_rate": 1.5202666666666668e-05,
      "loss": 0.4178,
      "step": 1800
    },
    {
      "epoch": 0.25333333333333335,
      "grad_norm": 2.6549441814422607,
      "learning_rate": 1.4936000000000002e-05,
      "loss": 0.4003,
      "step": 1900
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 9.396895408630371,
      "learning_rate": 1.4669333333333335e-05,
      "loss": 0.3508,
      "step": 2000
    },
    {
      "epoch": 0.28,
      "grad_norm": 5.911686420440674,
      "learning_rate": 1.4402666666666667e-05,
      "loss": 0.3814,
      "step": 2100
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 5.001821041107178,
      "learning_rate": 1.4136000000000002e-05,
      "loss": 0.3745,
      "step": 2200
    },
    {
      "epoch": 0.30666666666666664,
      "grad_norm": 2.7301576137542725,
      "learning_rate": 1.3869333333333335e-05,
      "loss": 0.3863,
      "step": 2300
    },
    {
      "epoch": 0.32,
      "grad_norm": 9.417855262756348,
      "learning_rate": 1.3602666666666668e-05,
      "loss": 0.3588,
      "step": 2400
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.8009694218635559,
      "learning_rate": 1.3336e-05,
      "loss": 0.3595,
      "step": 2500
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 11.271106719970703,
      "learning_rate": 1.3069333333333334e-05,
      "loss": 0.4062,
      "step": 2600
    },
    {
      "epoch": 0.36,
      "grad_norm": 5.807457447052002,
      "learning_rate": 1.2802666666666667e-05,
      "loss": 0.3512,
      "step": 2700
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 3.6294806003570557,
      "learning_rate": 1.2536000000000002e-05,
      "loss": 0.3763,
      "step": 2800
    },
    {
      "epoch": 0.38666666666666666,
      "grad_norm": 9.239789962768555,
      "learning_rate": 1.2269333333333335e-05,
      "loss": 0.36,
      "step": 2900
    },
    {
      "epoch": 0.4,
      "grad_norm": 4.9330830574035645,
      "learning_rate": 1.2002666666666668e-05,
      "loss": 0.3756,
      "step": 3000
    },
    {
      "epoch": 0.41333333333333333,
      "grad_norm": 6.910611629486084,
      "learning_rate": 1.1736e-05,
      "loss": 0.3429,
      "step": 3100
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 6.890413284301758,
      "learning_rate": 1.1469333333333334e-05,
      "loss": 0.3292,
      "step": 3200
    },
    {
      "epoch": 0.44,
      "grad_norm": 13.675416946411133,
      "learning_rate": 1.1202666666666669e-05,
      "loss": 0.3209,
      "step": 3300
    },
    {
      "epoch": 0.4533333333333333,
      "grad_norm": 7.343424320220947,
      "learning_rate": 1.0936e-05,
      "loss": 0.3231,
      "step": 3400
    },
    {
      "epoch": 0.4666666666666667,
      "grad_norm": 11.751693725585938,
      "learning_rate": 1.0669333333333333e-05,
      "loss": 0.385,
      "step": 3500
    },
    {
      "epoch": 0.48,
      "grad_norm": 7.874244689941406,
      "learning_rate": 1.0402666666666668e-05,
      "loss": 0.3343,
      "step": 3600
    },
    {
      "epoch": 0.49333333333333335,
      "grad_norm": 11.867219924926758,
      "learning_rate": 1.0136000000000001e-05,
      "loss": 0.3726,
      "step": 3700
    },
    {
      "epoch": 0.5066666666666667,
      "grad_norm": 15.581197738647461,
      "learning_rate": 9.869333333333334e-06,
      "loss": 0.3418,
      "step": 3800
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.367283821105957,
      "learning_rate": 9.602666666666669e-06,
      "loss": 0.3536,
      "step": 3900
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 25.64071273803711,
      "learning_rate": 9.336e-06,
      "loss": 0.3547,
      "step": 4000
    },
    {
      "epoch": 0.5466666666666666,
      "grad_norm": 6.779438495635986,
      "learning_rate": 9.069333333333335e-06,
      "loss": 0.3559,
      "step": 4100
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.8909528255462646,
      "learning_rate": 8.802666666666668e-06,
      "loss": 0.3469,
      "step": 4200
    },
    {
      "epoch": 0.5733333333333334,
      "grad_norm": 13.176094055175781,
      "learning_rate": 8.536000000000001e-06,
      "loss": 0.3671,
      "step": 4300
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 11.289371490478516,
      "learning_rate": 8.269333333333334e-06,
      "loss": 0.3553,
      "step": 4400
    },
    {
      "epoch": 0.6,
      "grad_norm": 13.909045219421387,
      "learning_rate": 8.002666666666667e-06,
      "loss": 0.3164,
      "step": 4500
    },
    {
      "epoch": 0.6133333333333333,
      "grad_norm": 1.199599266052246,
      "learning_rate": 7.736e-06,
      "loss": 0.3215,
      "step": 4600
    },
    {
      "epoch": 0.6266666666666667,
      "grad_norm": 7.068170070648193,
      "learning_rate": 7.469333333333334e-06,
      "loss": 0.3355,
      "step": 4700
    },
    {
      "epoch": 0.64,
      "grad_norm": 11.020549774169922,
      "learning_rate": 7.202666666666668e-06,
      "loss": 0.3234,
      "step": 4800
    },
    {
      "epoch": 0.6533333333333333,
      "grad_norm": 11.839978218078613,
      "learning_rate": 6.936e-06,
      "loss": 0.3082,
      "step": 4900
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 7.833714485168457,
      "learning_rate": 6.669333333333334e-06,
      "loss": 0.3123,
      "step": 5000
    },
    {
      "epoch": 0.68,
      "grad_norm": 4.320307731628418,
      "learning_rate": 6.402666666666667e-06,
      "loss": 0.3353,
      "step": 5100
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 1.1721464395523071,
      "learning_rate": 6.136000000000001e-06,
      "loss": 0.2905,
      "step": 5200
    },
    {
      "epoch": 0.7066666666666667,
      "grad_norm": 10.81157112121582,
      "learning_rate": 5.869333333333333e-06,
      "loss": 0.3541,
      "step": 5300
    },
    {
      "epoch": 0.72,
      "grad_norm": 17.79746437072754,
      "learning_rate": 5.602666666666667e-06,
      "loss": 0.3166,
      "step": 5400
    },
    {
      "epoch": 0.7333333333333333,
      "grad_norm": 2.9390811920166016,
      "learning_rate": 5.336e-06,
      "loss": 0.3171,
      "step": 5500
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 5.24591064453125,
      "learning_rate": 5.069333333333334e-06,
      "loss": 0.3546,
      "step": 5600
    },
    {
      "epoch": 0.76,
      "grad_norm": 5.9035115242004395,
      "learning_rate": 4.802666666666667e-06,
      "loss": 0.3222,
      "step": 5700
    },
    {
      "epoch": 0.7733333333333333,
      "grad_norm": 3.812852382659912,
      "learning_rate": 4.536e-06,
      "loss": 0.31,
      "step": 5800
    },
    {
      "epoch": 0.7866666666666666,
      "grad_norm": 1.7212212085723877,
      "learning_rate": 4.269333333333333e-06,
      "loss": 0.3027,
      "step": 5900
    },
    {
      "epoch": 0.8,
      "grad_norm": 7.6560211181640625,
      "learning_rate": 4.002666666666667e-06,
      "loss": 0.3199,
      "step": 6000
    },
    {
      "epoch": 0.8133333333333334,
      "grad_norm": 5.689203262329102,
      "learning_rate": 3.7360000000000003e-06,
      "loss": 0.3115,
      "step": 6100
    },
    {
      "epoch": 0.8266666666666667,
      "grad_norm": 6.712658882141113,
      "learning_rate": 3.4693333333333334e-06,
      "loss": 0.3071,
      "step": 6200
    },
    {
      "epoch": 0.84,
      "grad_norm": 7.091736793518066,
      "learning_rate": 3.202666666666667e-06,
      "loss": 0.3464,
      "step": 6300
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 11.82194709777832,
      "learning_rate": 2.9360000000000003e-06,
      "loss": 0.3206,
      "step": 6400
    },
    {
      "epoch": 0.8666666666666667,
      "grad_norm": 2.8641960620880127,
      "learning_rate": 2.669333333333334e-06,
      "loss": 0.3368,
      "step": 6500
    },
    {
      "epoch": 0.88,
      "grad_norm": 12.460476875305176,
      "learning_rate": 2.402666666666667e-06,
      "loss": 0.3379,
      "step": 6600
    },
    {
      "epoch": 0.8933333333333333,
      "grad_norm": 15.098045349121094,
      "learning_rate": 2.1360000000000004e-06,
      "loss": 0.3297,
      "step": 6700
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 3.9456701278686523,
      "learning_rate": 1.8693333333333337e-06,
      "loss": 0.3172,
      "step": 6800
    },
    {
      "epoch": 0.92,
      "grad_norm": 7.063733100891113,
      "learning_rate": 1.6026666666666667e-06,
      "loss": 0.3636,
      "step": 6900
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 11.445626258850098,
      "learning_rate": 1.336e-06,
      "loss": 0.2915,
      "step": 7000
    },
    {
      "epoch": 0.9466666666666667,
      "grad_norm": 5.259937286376953,
      "learning_rate": 1.0693333333333335e-06,
      "loss": 0.318,
      "step": 7100
    },
    {
      "epoch": 0.96,
      "grad_norm": 4.751305103302002,
      "learning_rate": 8.026666666666668e-07,
      "loss": 0.3419,
      "step": 7200
    },
    {
      "epoch": 0.9733333333333334,
      "grad_norm": 1.983300805091858,
      "learning_rate": 5.36e-07,
      "loss": 0.3421,
      "step": 7300
    },
    {
      "epoch": 0.9866666666666667,
      "grad_norm": 17.481489181518555,
      "learning_rate": 2.6933333333333336e-07,
      "loss": 0.3517,
      "step": 7400
    },
    {
      "epoch": 1.0,
      "grad_norm": 10.04834270477295,
      "learning_rate": 2.666666666666667e-09,
      "loss": 0.3207,
      "step": 7500
    }
  ],
  "logging_steps": 100,
  "max_steps": 7500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 38138388480000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
