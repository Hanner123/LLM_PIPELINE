stages:
  train:
    cmd: python code/tiny_train.py
    deps:
      - code/tiny_train.py
      - code/bert_dataset.py
    params:
      - train.batch_size
      - train.epochs
      - train.lr
      - train.d_model
      - train.heads
      - train.dropout
      - train.weight_decay
    outs:
      - models/tinybert_saved_model
  evaluate:
    cmd: python code/evaluate_model.py
    deps:
      - code/evaluate_model.py
      - models/tinybert_saved_model
  export:
    cmd: python code/export.py #_feste_batch_size.py
    deps:
      - code/export.py #_feste_batch_size.py
      - models/tinybert_saved_model
    outs: 
      - models/tinybert.onnx
  quantize:
    cmd: python code/brevitas_quant.py #_feste_batch_size.py
    deps:
      - code/brevitas_quant.py # muss ich hier auch die brevitas beispieldateien angeben?
      - models/tinybert_saved_model
    outs:
      - models/model.onnx
  measure:
    cmd: python code/measure_2.py #_feste_batch_size.py
    deps:
      - code/measure_2.py #_feste_batch_size.py
      - code/bar_1.json
      - code/bar_2.json
      - code/bar_3.json
      - code/bar_4.json
      - models/model.onnx
      - models/tinybert_saved_model
      - datasets/tokenized_agnews_test.pt
    plots:
     -  throughput/throughput_results.json:
         template: code/bar_2.json
         x: batch_size
         y: throughput_batches_per_s
         cache: false
     - throughput/throughput_results_2.json:
         template: code/bar_1.json
         x: batch_size
         y: throughput_images_per_s
         cache: false
     - throughput/latency_results.json:
         template: code/bar_3.json
         x: batch_size
         y: value
         cache: false
     - throughput/latency_results_batch.json:
         template: code/bar_4.json
         x: batch_size
         y: value
         cache: false

